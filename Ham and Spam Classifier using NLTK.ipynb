{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Text Processing with NLTK\n",
    "### Detecting either spam or ham using pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download_shell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Importing Text from Corpus and Convert into list in 'messages Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [line.rstrip() for line in open('smsspamcollection/SMSSpamCollection')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5574\n"
     ]
    }
   ],
   "source": [
    "print(len(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "\n",
      "1 ham\tOk lar... Joking wif u oni...\n",
      "\n",
      "\n",
      "2 spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "\n",
      "3 ham\tU dun say so early hor... U c already then say...\n",
      "\n",
      "\n",
      "4 ham\tNah I don't think he goes to usf, he lives around here though\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num,message in enumerate(messages[:5]):\n",
    "    print(num,message)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Since separator of each string was tab, we could convert them as dataframe using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = pd.read_csv('smsspamcollection/SMSSpamCollection',sep='\\t',names=['label','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4825   4516                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " msg.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg['length'] = msg['message'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plot length of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg['length'].plot.hist(bins=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.489950\n",
       "std        59.942907\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"For me the love should start with attraction.i should feel that I need her every time around me.she should be the first thing which comes in my thoughts.I would start the day and end it with her.she should be there every time I dream.love will be then when my every breath has her name.my life should happen around her.my life will be named to her.I would cry for her.will give all my happiness and take all her sorrows.I will be ready to fight with anyone for her.I will be in love when I will be doing the craziest things for her.love will be when I don't have to proove anyone that my girl is the most beautiful lady on the whole planet.I will always be singing praises for her.love will be when I start up making chicken curry and end up makiing sambar.life will be the most beautiful then.will get every morning and thank god for the day because she is with me.I would like to say a lot..will tell later..\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg[msg['length'] > 900]['message'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas data viz's subplot by column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:title={'center':'ham'}>,\n",
       "       <AxesSubplot:title={'center':'spam'}>], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg.hist(column='length',by='label',bins=60,figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *we could conclude that spam message character tend to have length longer than ham's character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess = 'Example Message ! Notice : Message, Contain a punctuation.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Processing \n",
    "### 2.1. Remove All Punctuation in Sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E',\n",
       " 'x',\n",
       " 'a',\n",
       " 'm',\n",
       " 'p',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'M',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 'g',\n",
       " 'e',\n",
       " ' ',\n",
       " ' ',\n",
       " 'N',\n",
       " 'o',\n",
       " 't',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " ' ',\n",
       " ' ',\n",
       " 'M',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 'a',\n",
       " 'g',\n",
       " 'e',\n",
       " ' ',\n",
       " 'C',\n",
       " 'o',\n",
       " 'n',\n",
       " 't',\n",
       " 'a',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'p',\n",
       " 'u',\n",
       " 'n',\n",
       " 'c',\n",
       " 't',\n",
       " 'u',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunc = [c for c in mess if c not in string.punctuation]\n",
    "nopunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Remove all stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Stopwords in NLTK is a list of collection word which does not add much meaning to a sentence. These word can safely be ignored without sacrificing the meaning of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Joining back a list into one string without a punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['a','b','c'] #Example usage of join in string function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a*b*c'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'*'.join(x)       #Join splitted string with separator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Apply join function into our list string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nopunc = ''.join(nopunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Example Message  Notice  Message Contain a punctuation'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Example', 'Message', 'Notice', 'Message', 'Contain', 'a', 'punctuation']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunc.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Clean any existing stopwords from our word list in nopunc with lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mess = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Example', 'Message', 'Notice', 'Message', 'Contain', 'punctuation']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_mess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Define a 'stopwords_removal' function to be applied to all column from our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(msg):\n",
    "    '''\n",
    "    1. Remove Punctuation\n",
    "    2. Remove Stop words\n",
    "    3. Return list of clean text words\n",
    "    '''\n",
    "    \n",
    "    nopunc = [c for c in msg if c not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    clean_msg = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    return clean_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Apply to our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1   ham                      Ok lar... Joking wif u oni...      29\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3   ham  U dun say so early hor... U c already then say...      49\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg['message'].head(5).apply(stopwords_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Vectorization (CountVectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *In here we're gonna transform our dataframe into a new dataframe (imagine 2-Dimensional Matrix, where 1 Dimensional is the entire vocabulary (1-Row per word) and the other dimension is the actual documents\n",
    "\n",
    "For example:\n",
    "\n",
    "<table border = “1“>\n",
    "<tr>\n",
    "<th></th> <th>Message 1</th> <th>Message 2</th> <th>...</th> <th>Message N</th> \n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 1 Count</b></td><td>0</td><td>1</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 2 Count</b></td><td>0</td><td>0</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>...</b></td> <td>1</td><td>2</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word N Count</b></td> <td>0</td><td>1</td><td>...</td><td>1</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **With count vectorizer we could count occurence of the word in a sentence, in this case we passing a previous function which removing any punctuation and stop words fit into our dataframe and convert into 2 Dimensional array where we could vectorize any word occurence in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below we initialize our Countvectorizer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags_transformer = CountVectorizer(analyzer=stopwords_removal).fit(msg['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11425\n"
     ]
    }
   ],
   "source": [
    "print(len(bags_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Take notice that we have 11425 unique word in our vocabulary based on for each message in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U dun say so early hor... U c already then say...']\n"
     ]
    }
   ],
   "source": [
    "msg4 = msg['message'][3]\n",
    "print([msg4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Apply our count vectorizer object on single message, (require input as iterable list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "bags4 = bags_transformer.transform([msg4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4068)\t2\n",
      "  (0, 4629)\t1\n",
      "  (0, 5261)\t1\n",
      "  (0, 6204)\t1\n",
      "  (0, 6222)\t1\n",
      "  (0, 7186)\t1\n",
      "  (0, 9554)\t2\n",
      "(1, 11425)\n"
     ]
    }
   ],
   "source": [
    "print(bags4)\n",
    "print(bags4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From a shape we could consider that in the [msg4] we're just passed in contain a word in vocabulary on index 4068,4629,...,9554. We could check for each index message, for example like below :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U\n",
      "say\n"
     ]
    }
   ],
   "source": [
    "print(bags_transformer.get_feature_names()[4068])\n",
    "print(bags_transformer.get_feature_names()[9554])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *In vocabulary index- 4068 is a word 'U' which 2 times occurence, as we could see in the sentences we're passed in :\n",
    "['U dun say so early hor... U c already then say...']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Now we could transform the entire DataFrame Messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_bags = bags_transformer.transform(msg['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (5572, 11425)\n",
      "Amount of Non-Zero occurences:  50548\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', msg_bags.shape)\n",
    "print('Amount of Non-Zero occurences: ', msg_bags.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0\n"
     ]
    }
   ],
   "source": [
    "sparsity = (100.0 * msg_bags.nnz / (msg_bags.shape[0] * msg_bags.shape[1]))\n",
    "print('sparsity: {}'.format(round(sparsity)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. TF-IDF?\n",
    "TF-IDF stands for *term frequency-inverse document frequency*, and the tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus. Variations of the tf-idf weighting scheme are often used by search engines as a central tool in scoring and ranking a document's relevance given a user query.\n",
    "\n",
    "**TF: Term Frequency**, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization: \n",
    "\n",
    "*TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).*\n",
    "\n",
    "**IDF: Inverse Document Frequency**, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following: \n",
    "\n",
    "*IDF(t) = log_e(Total number of documents / Number of documents with term t in it).*\n",
    "\n",
    "See below for a simple example.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Consider a document containing 100 words wherein the word cat appears 3 times. \n",
    "\n",
    "The term frequency (i.e., tf) for cat is then (3 / 100) = 0.03. Now, assume we have 10 million documents and the word cat appears in one thousand of these. Then, the inverse document frequency (i.e., idf) is calculated as log(10,000,000 / 1,000) = 4. Thus, the Tf-idf weight is the product of these quantities: 0.03 * 4 = 0.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(msg_bags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Transform Word Frequencies of bags4 into Tfidf, remember that bags4 contain a occurencies of each word message 4, and we're gonna turn into tfidf, these number represent as a weight value for each these word vs actual document (entire word in document transformer vs msg4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U dun say so early hor... U c already then say...']\n"
     ]
    }
   ],
   "source": [
    "print([msg4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9554)\t0.5385626262927564\n",
      "  (0, 7186)\t0.4389365653379857\n",
      "  (0, 6222)\t0.3187216892949149\n",
      "  (0, 6204)\t0.29953799723697416\n",
      "  (0, 5261)\t0.29729957405868723\n",
      "  (0, 4629)\t0.26619801906087187\n",
      "  (0, 4068)\t0.40832589933384067\n"
     ]
    }
   ],
   "source": [
    "tfidf4 = tfidf_transformer.transform(bags4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2800524267409408\n",
      "8.527076498901426\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_transformer.idf_[bags_transformer.vocabulary_['u']])\n",
    "print(tfidf_transformer.idf_[bags_transformer.vocabulary_['university']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(msg_bags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Spam vs Ham detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using naive bayes detector we pass entire tfidf of dataframe, and label column of msg as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_detect_model = MultinomialNB().fit(messages_tfidf,msg['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Try to classify of tfidf4 of message ['U dun say so early hor... U c already then say...'] either it is ham or spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_detect_model.predict(tfidf4)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg['label'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Predicted label of msg4 is ham and actual expected label is also ham, this because we trained entire all dataset and testing/evaluate a data which contain/same in training data that in real we should never done that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = spam_detect_model.predict(messages_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proper way to do measure evaluation of prediction we should use train and split as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train,msg_test,label_train,label_test = train_test_split(msg['message'],msg['label'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5336    Sounds better than my evening im just doing my...\n",
       "4144    In The Simpsons Movie released in July 2007 na...\n",
       "5363    I think your mentor is , but not 100 percent s...\n",
       "246     Too late. I said i have the website. I didn't ...\n",
       "4156    Want a new Video Phone? 750 anytime any networ...\n",
       "                              ...                        \n",
       "1396    Thats cool! I am a gentleman and will treat yo...\n",
       "306     Yup... From what i remb... I think should be c...\n",
       "2587    If you don't respond imma assume you're still ...\n",
       "2023    U can WIN £100 of Music Gift Vouchers every we...\n",
       "436     The message sent is askin for  &lt;#&gt; dolla...\n",
       "Name: message, Length: 3900, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Take a note as usual if we want to perform train and evaluate the model(text-based data) we need to repeat previous step such remove stop_words, punctuation, do Vectorization in this case CountVectorizer (bags_transformer) and do TFIDF to obatain weighted per word vs entire data, but instead we could use train pipeline that we don't need to repeat these process again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=stopwords_removal)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Instead doing manual all process we use pipeline where we define per every process within, we no longer worried about manually doing count vectorization or tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function stopwords_removal at 0x7f20cd6aab70>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_predict = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1452\n",
      "        spam       1.00      0.74      0.85       220\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.98      0.87      0.91      1672\n",
      "weighted avg       0.97      0.97      0.96      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test,pipe_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** we also can use another classifier such random forest, etc..\n",
    "#### Basically pipeline is just a shorten way to encapsulate these sequential steps.\n",
    "\n",
    "Now instead of using this function below :\n",
    "***\n",
    "<br>vect = CountVectorizer()\n",
    "<br>tfidf = TfidfTransformer()\n",
    "<br>clf = SGDClassifier()\n",
    "\n",
    "<br>vX = vect.fit_transform(Xtrain)\n",
    "<br>tfidfX = tfidf.fit_transform(vX)\n",
    "<br>predicted = clf.fit_predict(tfidfX)\n",
    "\n",
    "<br>vX = vect.fit_transform(Xtest)\n",
    "<br>tfidfX = tfidf.fit_transform(vX)\n",
    "<br>predicted = clf.fit_predict(tfidfX)\n",
    "***\n",
    "it would rather using pipeline :\n",
    "***\n",
    "<br>pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "<br>predicted = pipeline.fit(Xtrain).predict(Xtrain)\n",
    "<br>predicted = pipeline.predict(Xtest)\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
